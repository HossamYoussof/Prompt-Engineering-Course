{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DEAKbfqmGK7"
      },
      "source": [
        "# **HuggingFace Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-c_lGHDJXuk"
      },
      "source": [
        "## installation\n",
        "https://python.langchain.com/docs/integrations/chat/huggingface/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "56V5zok8sT8q"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# https://huggingface.co/settings/tokens\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=userdata.get('huggingToken')\n",
        "\n",
        "if \"HUGGINGFACEHUB_API_TOKEN\" not in os.environ:\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain-huggingface text-generation transformers google-search-results numexpr langchainhub sentencepiece jinja2 bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "9Ghiw7Q5prpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05d77d8-9370-420a-ef19-82e40bb56997"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n",
        "\n",
        "# https://huggingface.co/microsoft/Phi-3-mini-4k-instruct\n",
        "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=\"float16\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=model_id,\n",
        "    task=\"text-generation\",\n",
        "    pipeline_kwargs=dict(\n",
        "        max_new_tokens=512,\n",
        "        do_sample=False,\n",
        "        repetition_penalty=1.03,\n",
        "        return_full_text=False,\n",
        "    ),\n",
        "    model_kwargs={\"quantization_config\": quantization_config},\n",
        ")\n",
        "\n",
        "chat_model = ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "kiUTQ_b1pxAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz6jdc9JJeUy"
      },
      "source": [
        "## Listing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nFUDQRQEyaF-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "626040ab-f20a-4709-a026-332bba4f3762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Three popular Arabian plates are:\\n\\n1. Mansaf - A traditional Jordanian dish made with lamb cooked in a sauce of fermented dried yogurt and served over rice or flatbread.\\n2. Kabsa - A Saudi Arabian dish consisting of rice, meat (usually chicken, lamb, or fish), and a blend of spices.\\n3. Mandi - An Emirati dish that is similar to mansaf but uses camel meat instead of lamb. It's typically served with rice and a yogurt-based sauce.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "task = \"List three popular Arabian plates.\"\n",
        "\n",
        "# Chat response\n",
        "ai_response = chat_model.invoke(task)\n",
        "ai_response.content\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
        "\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "format_instuctions = output_parser.get_format_instructions()\n",
        "\n",
        "propmt = PromptTemplate(\n",
        "    template=\"List three popular {type} plates.\\n{format_instructions}\",\n",
        "    input_variables=[\"type\"],\n",
        "    partial_variables={\"format_instructions\": format_instuctions}\n",
        ")\n",
        "\n",
        "# propmt = PromptTemplate(\n",
        "#     template=\"List three popular {type} plates.\",\n",
        "#     input_variables=[\"type\"],\n",
        "# )\n",
        "\n",
        "demo_message = propmt.format(type=\"Arabian\")\n",
        "print(\"Prompt: \" + demo_message)\n"
      ],
      "metadata": {
        "id": "1v9YmK4fhXj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14228075-877f-4cdc-939c-590f2bf55f26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: List three popular Arabian plates.\n",
            "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat response\n",
        "ai_response = chat_model.invoke(demo_message)\n",
        "print(\"AI: \" + ai_response.content)"
      ],
      "metadata": {
        "id": "26QjLeyduxll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda1a78d-3fc1-4245-e960-42115f709960"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI:  Chicken Shawarma, Hummus and Falafel, Biryani\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output\n",
        "output = output_parser.parse(ai_response.content)\n",
        "print(\"Output value: \" + str(output))\n",
        "\n",
        "# Print output type like \"Output type: \"\n",
        "print(\"Output type: \" + str(type(output)))\n"
      ],
      "metadata": {
        "id": "mIKXkvJlx67L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f18f920-5f29-46ed-e322-c4c64d4c41ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output value: ['Chicken Shawarma', 'Hummus and Falafel', 'Biryani']\n",
            "Output type: <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DateTime"
      ],
      "metadata": {
        "id": "HiZm1Gh72nza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "format_instruction = \"Replay with the date in DAY/MONTH/YEAR format. like '23/05/1988'\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"When was {person} born?\\n{format_instruction}\",\n",
        "    input_variables=['person', 'format_instruction'],\n",
        ")\n",
        "\n",
        "message = prompt.format(person=\"Thomas Edison\", format_instruction=format_instruction)\n",
        "\n",
        "ai_response = chat_model.invoke(message)\n",
        "ai_response.content"
      ],
      "metadata": {
        "id": "tgm53sXp2wXp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd22f8a2-e3ee-4a4e-e2b7-a3712153e4da"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 10/08/1847'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyDantic"
      ],
      "metadata": {
        "id": "OVCP1NjX8Xqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "class Plate(BaseModel):\n",
        "  plate_name: str = Field(description=\"name of the plate\")\n",
        "  ingredients: List[str] = Field(description=\"list of names of the ingredients\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Plate)\n",
        "\n",
        "format_instructions = parser.get_format_instructions()\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the query.\\n{plate_name}?\\n{format_instructions}\",\n",
        "    input_variables=[\"plate_name\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")\n",
        "\n",
        "plate_name = 'Shawerma'\n",
        "\n",
        "message = prompt.format(plate_name=plate_name)\n",
        "print(\"meaage: \" + message)\n",
        "\n"
      ],
      "metadata": {
        "id": "gPDWAtd98gZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a43fe8-174e-445d-e969-cf6c9533723e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meaage: Answer the query.\n",
            "Shawerma?\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"plate_name\": {\"description\": \"name of the plate\", \"title\": \"Plate Name\", \"type\": \"string\"}, \"ingredients\": {\"description\": \"list of names of the ingredients\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}}, \"required\": [\"plate_name\", \"ingredients\"]}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_response = chat_model.invoke(message)\n",
        "print(\"AI: \" + str(ai_response.content))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDL5us1a2q-d",
        "outputId": "41214bfa-03bf-43de-950e-afa6af399c78"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI:  ```json\n",
            "{\n",
            "  \"plate_name\": \"Shawerma\",\n",
            "  \"ingredients\": [\"shrimp\", \"avocado\", \"lime\", \"tomato\", \"cucumber\", \"mayonnaise\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = parser.parse(ai_response.content)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wtFOPgC2tiU",
        "outputId": "5612104e-d7bd-4106-80c9-d6de9446fde8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Plate(plate_name='Shawerma', ingredients=['shrimp', 'avocado', 'lime', 'tomato', 'cucumber', 'mayonnaise'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.plate_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wNgGGNnD2x_u",
        "outputId": "d555e6a5-774b-4ff2-e1b4-260c9b93752d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Shawerma'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.ingredients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF8YZLpf22Ty",
        "outputId": "f1ef7bb1-5207-466e-b7d9-c9115d8b4c50"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['shrimp', 'avocado', 'lime', 'tomato', 'cucumber', 'mayonnaise']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}