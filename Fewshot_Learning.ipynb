{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DEAKbfqmGK7"
      },
      "source": [
        "# **HuggingFace Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-c_lGHDJXuk"
      },
      "source": [
        "## installation\n",
        "https://python.langchain.com/docs/integrations/chat/huggingface/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "56V5zok8sT8q"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# https://huggingface.co/settings/tokens\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=userdata.get('huggingToken')\n",
        "\n",
        "if \"HUGGINGFACEHUB_API_TOKEN\" not in os.environ:\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g4-CYHkVr-kB"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet langchain-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz6jdc9JJeUy"
      },
      "source": [
        "## Basic FewShots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
        "\n",
        "repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.03,\n",
        ")\n",
        "\n",
        "chat = ChatHuggingFace(llm=llm, verbose=True)"
      ],
      "metadata": {
        "id": "IpTj7cec_i3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570449ae-09fd-427d-ab76-bd2eaae823a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nFUDQRQEyaF-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f626706f-ad8f-4427-f699-b9b4fa665df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Egypt - Cairo\\nFrance - Paris\\nItaly - Rome\\nJapan - Tokyo\\nUSA - Washington D.C.\\nMorocco - Rabat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "demo_message = \"\"\"\n",
        "Country name: Egypt | Captital name: Cairo\n",
        "Country name: France | Captital name: Paris\n",
        "Country name: Italy | Captital name: Rome\n",
        "Country name: Japan | Captital name: Tokyo\n",
        "Country name: USA | Captital name: Washington D.C.\n",
        "Country name: Morocco | Captital name:\n",
        "\"\"\".strip()\n",
        "\n",
        "ai_response = chat.invoke(demo_message)\n",
        "ai_response.content\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_template = PromptTemplate(\n",
        "    template=\"Country name: {country} | Captital name: {capital}\",\n",
        "    input_variables=[\"country\", \"capital\"],\n",
        ")\n",
        "\n",
        "examples = [\n",
        "    {\"country\": \"Egypt\", \"capital\": \"Cairo\"},\n",
        "    {\"country\": \"France\", \"capital\": \"Paris\"},\n",
        "    {\"country\": \"Italy\", \"capital\": \"Rome\"},\n",
        "]\n",
        "\n",
        "prompt = FewShotPromptTemplate(\n",
        "    example_prompt=demo_template,\n",
        "    examples=examples,\n",
        "    suffix=\"Country name: {country} | Captital name:\",\n",
        "    input_variables=[\"country\"],\n",
        ")\n",
        "\n",
        "user_input = \"Japan\"\n",
        "\n",
        "message=prompt.format(country=user_input)\n",
        "\n",
        "# print(message)\n",
        "\n",
        "ai_response = chat.invoke(message)\n",
        "ai_response.content\n",
        "\n"
      ],
      "metadata": {
        "id": "1v9YmK4fhXj4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90d8174b-a3df-444b-84d9-d1c97fdee5fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Country name: Japan | Captial name: Tokyo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fewshot Learning"
      ],
      "metadata": {
        "id": "fdynn2GO61GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "problem_prompt=\"When I was seven, my sister was twice my age. Now I am seventy years old, how old can my sister be?\"\n",
        "\n",
        "ai_response = chat.invoke(problem_prompt)\n",
        "ai_response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "ouTFCSGB6zpT",
        "outputId": "4e29adff-5c69-414d-fbf0-e9aa60ad300a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'When you were seven, your sister was twice your age, meaning she was 14 years old. The difference in age between you and your sister would have remained constant. That means your sister was 14 - 7 = 7 years older than you. Now that you are seventy, your sister would be 70 + 7 = 77 years old.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}