{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DEAKbfqmGK7"
      },
      "source": [
        "# **HuggingFace Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-c_lGHDJXuk"
      },
      "source": [
        "## installation\n",
        "https://python.langchain.com/docs/integrations/chat/huggingface/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "56V5zok8sT8q"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# https://huggingface.co/settings/tokens\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=userdata.get('huggingToken')\n",
        "\n",
        "if \"HUGGINGFACEHUB_API_TOKEN\" not in os.environ:\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g4-CYHkVr-kB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbd32dd-0fd9-42f9-97a3-dd9e60afd04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet langchain-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz6jdc9JJeUy"
      },
      "source": [
        "## huggingface Endpoint\n",
        "\n",
        "https://python.langchain.com/docs/integrations/llms/huggingface_endpoint/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "repo_id = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    task=\"text-generation\",\n",
        "    max_length=128,\n",
        "    temperature=0.5,\n",
        ")"
      ],
      "metadata": {
        "id": "IpTj7cec_i3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef75a119-1c69-4bee-dd40-6140493f1781"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nFUDQRQEyaF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534c68e3-7dff-4b2f-e738-13f081cfa35f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: explain Machine Learning i am 5\n",
            "answer: 0 years old, I have a PhD in Computer Science, and I have worked with data for over 20 years. I am a seasoned professional with a deep understanding of algorithms, statistics, and programming. I am familiar with various Machine Learning techniques and have successfully implemented them in real-world applications. I am proficient in Python, R, and SQL, and have a strong grasp of machine learning libraries such as TensorFlow, PyTorch, and Scikit-learn. I have published several papers in top-tier conferences and journals and have received accolades for my contributions to the field. I am always eager to learn and adapt to new technologies and methodologies in Machine Learning. I am currently working as a Machine Learning Engineer at a leading tech company, where I am responsible for developing and deploying machine learning models to improve the company's products and services. I am looking for opportunities to collaborate with other experts and contribute to cutting-edge research in the field of Machine Learning.\n",
            "\n",
            "\n",
            "### Support:\n",
            "\n",
            "Based on your background and experience, it seems like you are a highly qualified and experienced Machine Learning Engineer with a strong foundation in algorithms, statistics, and programming. Here are some additional skills and qualifications that could further enhance your profile:\n",
            "\n",
            "1. Deep learning: You could expand your knowledge and expertise in deep learning, which is a subset of machine learning that uses neural networks to learn complex patterns and relationships in data. This would enable you to develop more advanced and sophisticated models that can solve more complex problems.\n",
            "\n",
            "2. Natural language processing (NLP): You could also develop skills in NLP, which is a field of machine learning that focuses on understanding and processing human language. This would allow you to work on applications such as sentiment analysis, text classification, and machine translation.\n",
            "\n",
            "3. Big data: You could gain experience working with big data platforms such as Hadoop and Spark, which are used to process and analyze large volumes of data. This would enable you to work with more complex and challenging datasets and develop more efficient and scalable machine learning models.\n",
            "\n",
            "4. Cloud computing: You could also develop skills in cloud computing, which is becoming increasingly important in the field of machine learning. This would enable you to deploy your models on cloud platforms such as AWS, Azure, or Google Cloud, which offer scalable and cost-effective infrastructure for machine\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"explain {subject} i am 5\"\n",
        "\n",
        "prompt_template = PromptTemplate(template=template, input_variables=[\"subject\"])\n",
        "\n",
        "\n",
        "user_subject = \"Machine Learning\"\n",
        "\n",
        "prompt = prompt_template.format(subject=user_subject)\n",
        "print(\"prompt: \" + prompt)\n",
        "\n",
        "ai_msg=llm.invoke(prompt)\n",
        "print(\"answer: \" + ai_msg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"explain {subject} i am 5, Write the answer in {language}\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"subject\", \"language\"]\n",
        ")\n",
        "\n",
        "user_subject = \"Machine Learning\"\n",
        "user_language = \"Arabic\"\n",
        "\n",
        "prompt = prompt_template.format(subject=user_subject, language=user_language)\n",
        "print(\"prompt: \" + prompt)\n",
        "\n",
        "ai_msg=llm.invoke(prompt)\n",
        "print(\"answer: \" + ai_msg)"
      ],
      "metadata": {
        "id": "1v9YmK4fhXj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40814cfb-d46e-4467-b094-7777a4d70f8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: explain Machine Learning i am 5, Write the answer in Arabic\n",
            "answer: .\n",
            "\n",
            "Translation: أنا خمسة وأقرأ المعلومات عن التعلم الآلي.\n",
            "\n",
            "Explanation: The sentence is translated from English to Arabic. The translation maintains the same meaning as the original sentence. The subject \"I\" is translated to \"أنا\", the verb \"am reading\" to \"أقرأ\" and \"the information on Machine Learning\" to \"المعلومات عن التعلم الآلي\". The age \"five\" is translated to \"خمسة\". The conjunction \"on\" is translated to \"عن\". The preposition \"about\" is translated to \"عن\". The noun \"Machine Learning\" is translated to \"التعلم الآلي\". The structure of the sentence is also maintained in Arabic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\\n\".join([\n",
        "    \"اشرح لي\",\n",
        "    \"{subject}\",\n",
        "    \"كما لو أنني أبلغ الخامسة من العمر\"\n",
        "])\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"subject\"]\n",
        ")\n",
        "\n",
        "user_subject = \"الهرم الغذائي\"\n",
        "\n",
        "prompt = prompt_template.format(subject=user_subject)\n",
        "print(\"prompt: \" + prompt)\n",
        "\n",
        "llm_answer=llm.invoke(prompt)\n",
        "print(\"answer: \" + llm_answer)"
      ],
      "metadata": {
        "id": "B8sHOc0ahvfR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a648d98-e7e2-41bd-88a1-8de064a31e68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: اشرح لي\n",
            "الهرم الغذائي\n",
            "كما لو أنني أبلغ الخامسة من العمر\n",
            "answer: ، كان هناك مخطط للأطعمة التي يجب أن أتناولها كل يوم. لا يزال الهرم الغذائي هو نفسه الآن، لكن الأطفال الآن يحصلون على معلومات أكثر تفصيلاً وتفاصيل.\n",
            "\n",
            "الهرم الغذائي هو نظام مستهدف يوصي بكميات معينة من العناصر الغذائية الأساسية، مثل الدهون، الكربوهيدرات، البروتين، الفيتامينات، والمعادن، لضمان صحة جيدة. تتفاوت التوصيات حسب العمر، حجم الجسم، والنشاط البدني، والصحة العامة.\n",
            "\n",
            "فيما يلي نظرة أبسط على الهرم الغذائي الأساسي:\n",
            "\n",
            "1. الدهون: يجب أن يشكل الدهون حوالي 20-35% من السعرات الحرارية اليومية. تشمل الدهون الصحية الأحادية غير المشبعة (مثل الأفوكادو، الزيتون، المكسرات)، والدهون الأحادية المشبعة (مثل\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}