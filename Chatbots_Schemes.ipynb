{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DEAKbfqmGK7"
      },
      "source": [
        "# **HuggingFace Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-c_lGHDJXuk"
      },
      "source": [
        "## installation\n",
        "https://python.langchain.com/docs/integrations/chat/huggingface/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56V5zok8sT8q"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# https://huggingface.co/settings/tokens\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=userdata.get('huggingToken')\n",
        "\n",
        "if \"HUGGINGFACEHUB_API_TOKEN\" not in os.environ:\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4-CYHkVr-kB"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet langchain-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz6jdc9JJeUy"
      },
      "source": [
        "## Chat\n",
        "- System: Context or Background information\n",
        "- Human: Message from the user\n",
        "- AI: Message from llm\n",
        "\n",
        "https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
        "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage\n",
        "\n",
        "repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.03,\n",
        ")\n",
        "\n",
        "chat = ChatHuggingFace(llm=llm, verbose=True)"
      ],
      "metadata": {
        "id": "IpTj7cec_i3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFUDQRQEyaF-"
      },
      "outputs": [],
      "source": [
        "base_conversation = [\n",
        "    SystemMessage(content=\"You are a chief, you want to ask me some things to find out my favorite Asian dish\"),\n",
        "    AIMessage(content=\"Where are you from?\"),\n",
        "    HumanMessage(content=\"Egypt\"),\n",
        "    AIMessage(content=\"Do you like spicy food?\"),\n",
        "    HumanMessage(content=\"Not too much\"),\n",
        "    AIMessage(content=\"Do you suffer from diabetes?\"),\n",
        "    HumanMessage(content=\"Yes\"),\n",
        "]\n",
        "\n",
        "ai_response = chat.invoke(base_conversation)\n",
        "ai_response\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_conversation = [\n",
        "    SystemMessage(content=\"You are a chief, you want to ask me (short questions, one by one) some things to find out my favorite Asian dish, let's start the first question\"),\n",
        "]\n",
        "\n",
        "ai_response = None\n",
        "\n",
        "\n",
        "for i in range(3):\n",
        "\n",
        "  ai_response = chat.invoke(base_conversation)\n",
        "\n",
        "  print(\"AI: \", ai_response.content)\n",
        "\n",
        "  base_conversation.append(ai_response)\n",
        "\n",
        "  user_response = HumanMessage(content=input(\"Your answer: \"))\n",
        "  base_conversation.append(user_response)\n",
        "\n",
        "human_final_message = HumanMessage(content=\"And now. Which plate do you think I will like, Just type the plate name.\")\n",
        "\n",
        "base_conversation.append(human_final_message)\n",
        "\n",
        "ai_response = chat.invoke(base_conversation)\n",
        "\n",
        "print(\"AI: \", ai_response.content)\n"
      ],
      "metadata": {
        "id": "1v9YmK4fhXj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_conversation"
      ],
      "metadata": {
        "id": "B8sHOc0ahvfR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}